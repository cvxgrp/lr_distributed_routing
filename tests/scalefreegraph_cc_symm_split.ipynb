{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/parshakova.tanya/opt/anaconda3/envs/routing/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import osmnx as ox\n",
    "import networkx as nx\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "import pickle, time\n",
    "import pymde\n",
    "from sklearn.manifold import MDS, Isomap, TSNE, LocallyLinearEmbedding, SpectralEmbedding\n",
    "from scipy import sparse\n",
    "\n",
    "import mlrfit as mf\n",
    "import lrrouting as ldr\n",
    "\n",
    "import cvxpy as cp\n",
    "import numba as nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1001)\n",
    "random.seed(1001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Matrix definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=7020, G.number_of_edges()=23853\n",
      "[572, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "n_cc = 572, n0 = 7020\n",
      "in  degrees: {0: 0, 1: 183, 2: 128, 3: 76, 4: 47, 5: 35, 6: 23, 7: 6, 8: 12, 9: 15, 10: 2, 11: 6, 12: 5, 13: 4, 14: 3, 15: 8, 16: 1, 17: 2, 18: 2, 19: 1, 20: 3, 21: 0, 22: 0, 23: 1, 24: 1, 25: 1, 26: 0, 27: 0, 28: 1, 29: 1, 30: 0, 31: 0, 32: 0, 33: 0, 34: 0, 35: 0, 36: 0, 37: 0, 38: 0, 39: 0, 40: 0, 41: 1, 42: 0, 43: 1, 44: 0, 45: 0, 46: 0, 47: 0, 48: 0, 49: 0, 50: 1, 51: 0, 52: 0, 53: 0, 54: 0, 55: 0, 56: 0, 57: 0, 58: 0, 59: 0, 60: 0, 61: 0, 62: 0, 63: 0, 64: 0, 65: 0, 66: 0, 67: 0, 68: 0, 69: 0, 70: 0, 71: 0, 72: 0, 73: 0, 74: 0, 75: 0, 76: 0, 77: 0, 78: 0, 79: 0, 80: 0, 81: 0, 82: 0, 83: 0, 84: 0, 85: 0, 86: 0, 87: 0, 88: 0, 89: 0, 90: 0, 91: 0, 92: 0, 93: 0, 94: 0, 95: 0, 96: 0, 97: 0, 98: 0, 99: 0, 100: 0, 101: 0, 102: 0, 103: 0, 104: 0, 105: 0, 106: 0, 107: 0, 108: 0, 109: 0, 110: 0, 111: 0, 112: 0, 113: 0, 114: 0, 115: 0, 116: 0, 117: 0, 118: 0, 119: 0, 120: 0, 121: 0, 122: 0, 123: 0, 124: 0, 125: 0, 126: 0, 127: 0, 128: 0, 129: 0, 130: 0, 131: 0, 132: 0, 133: 0, 134: 0, 135: 0, 136: 0, 137: 1, 138: 0, 139: 0, 140: 0, 141: 0, 142: 0, 143: 0, 144: 0, 145: 0, 146: 0, 147: 0, 148: 0, 149: 0, 150: 0, 151: 0, 152: 0, 153: 0, 154: 0, 155: 0, 156: 0, 157: 0, 158: 0, 159: 0, 160: 0, 161: 0, 162: 0, 163: 0, 164: 0, 165: 0, 166: 0, 167: 0, 168: 0, 169: 0, 170: 0, 171: 0, 172: 0, 173: 0, 174: 0, 175: 0, 176: 0, 177: 0, 178: 0, 179: 0, 180: 0, 181: 0, 182: 0, 183: 0, 184: 0, 185: 0, 186: 0, 187: 0, 188: 0, 189: 0, 190: 0, 191: 0, 192: 0, 193: 0, 194: 0, 195: 0, 196: 0, 197: 0, 198: 0, 199: 0, 200: 0, 201: 0, 202: 0, 203: 0, 204: 0, 205: 0, 206: 0, 207: 0, 208: 0, 209: 0, 210: 0, 211: 0, 212: 0, 213: 0, 214: 0, 215: 0, 216: 0, 217: 0, 218: 0, 219: 0, 220: 0, 221: 0, 222: 0, 223: 0, 224: 0, 225: 0, 226: 0, 227: 0, 228: 0, 229: 0, 230: 0, 231: 0, 232: 0, 233: 0, 234: 0, 235: 0, 236: 0, 237: 0, 238: 0, 239: 0, 240: 0, 241: 0, 242: 0, 243: 0, 244: 0, 245: 0, 246: 0, 247: 0, 248: 0, 249: 0, 250: 0, 251: 0, 252: 0, 253: 0, 254: 0, 255: 0, 256: 0, 257: 0, 258: 0, 259: 0, 260: 0, 261: 0, 262: 0, 263: 0, 264: 0, 265: 0, 266: 0, 267: 0, 268: 0, 269: 0, 270: 0, 271: 0, 272: 0, 273: 1}\n",
      "out degrees: {0: 0, 1: 302, 2: 105, 3: 56, 4: 23, 5: 12, 6: 14, 7: 9, 8: 7, 9: 4, 10: 7, 11: 3, 12: 2, 13: 4, 14: 2, 15: 2, 16: 2, 17: 3, 18: 1, 19: 1, 20: 1, 21: 2, 22: 0, 23: 1, 24: 1, 25: 1, 26: 0, 27: 0, 28: 0, 29: 0, 30: 0, 31: 0, 32: 1, 33: 0, 34: 0, 35: 1, 36: 1, 37: 0, 38: 0, 39: 0, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 0, 48: 0, 49: 0, 50: 0, 51: 0, 52: 0, 53: 0, 54: 0, 55: 0, 56: 0, 57: 0, 58: 0, 59: 0, 60: 0, 61: 0, 62: 0, 63: 0, 64: 0, 65: 0, 66: 0, 67: 0, 68: 0, 69: 0, 70: 0, 71: 0, 72: 0, 73: 0, 74: 0, 75: 0, 76: 0, 77: 0, 78: 0, 79: 0, 80: 0, 81: 0, 82: 0, 83: 0, 84: 0, 85: 0, 86: 0, 87: 0, 88: 1, 89: 0, 90: 0, 91: 0, 92: 0, 93: 0, 94: 0, 95: 0, 96: 0, 97: 0, 98: 0, 99: 0, 100: 0, 101: 0, 102: 0, 103: 0, 104: 0, 105: 0, 106: 0, 107: 0, 108: 0, 109: 0, 110: 0, 111: 0, 112: 0, 113: 0, 114: 0, 115: 0, 116: 0, 117: 0, 118: 0, 119: 0, 120: 0, 121: 0, 122: 0, 123: 0, 124: 0, 125: 0, 126: 0, 127: 0, 128: 0, 129: 0, 130: 0, 131: 0, 132: 0, 133: 0, 134: 0, 135: 0, 136: 0, 137: 1, 138: 0, 139: 0, 140: 0, 141: 0, 142: 0, 143: 0, 144: 0, 145: 0, 146: 0, 147: 0, 148: 0, 149: 0, 150: 0, 151: 0, 152: 0, 153: 0, 154: 0, 155: 0, 156: 0, 157: 0, 158: 0, 159: 0, 160: 0, 161: 0, 162: 0, 163: 0, 164: 0, 165: 0, 166: 0, 167: 0, 168: 0, 169: 0, 170: 0, 171: 0, 172: 0, 173: 0, 174: 0, 175: 0, 176: 0, 177: 0, 178: 0, 179: 0, 180: 0, 181: 0, 182: 0, 183: 0, 184: 0, 185: 0, 186: 0, 187: 0, 188: 0, 189: 0, 190: 0, 191: 0, 192: 0, 193: 0, 194: 0, 195: 0, 196: 0, 197: 0, 198: 0, 199: 0, 200: 0, 201: 0, 202: 0, 203: 0, 204: 0, 205: 0, 206: 0, 207: 0, 208: 0, 209: 0, 210: 0, 211: 0, 212: 0, 213: 0, 214: 0, 215: 0, 216: 0, 217: 0, 218: 0, 219: 0, 220: 0, 221: 0, 222: 0, 223: 0, 224: 0, 225: 0, 226: 0, 227: 0, 228: 0, 229: 0, 230: 0, 231: 0, 232: 0, 233: 0, 234: 0, 235: 0, 236: 0, 237: 0, 238: 0, 239: 0, 240: 0, 241: 0, 242: 0, 243: 0, 244: 0, 245: 0, 246: 0, 247: 0, 248: 0, 249: 0, 250: 0, 251: 0, 252: 0, 253: 0, 254: 0, 255: 0, 256: 0, 257: 0, 258: 0, 259: 0, 260: 0, 261: 0, 262: 0, 263: 0, 264: 0, 265: 0, 266: 0, 267: 0, 268: 0, 269: 0, 270: 0, 271: 0, 272: 0, 273: 0, 274: 0, 275: 0, 276: 0, 277: 0, 278: 0, 279: 0, 280: 0, 281: 0, 282: 0, 283: 0, 284: 0, 285: 0, 286: 0, 287: 0, 288: 0, 289: 0, 290: 0, 291: 0, 292: 0, 293: 0, 294: 0, 295: 0, 296: 0, 297: 0, 298: 1, 299: 0, 300: 0, 301: 0, 302: 0, 303: 0, 304: 0, 305: 0, 306: 0, 307: 0, 308: 0, 309: 0, 310: 0, 311: 0, 312: 0, 313: 0, 314: 0, 315: 0, 316: 0, 317: 0, 318: 0, 319: 0, 320: 0, 321: 0, 322: 0, 323: 0, 324: 0, 325: 0, 326: 0, 327: 0, 328: 0, 329: 0, 330: 0, 331: 0, 332: 0, 333: 0, 334: 0, 335: 0, 336: 0, 337: 0, 338: 0, 339: 0, 340: 0, 341: 0, 342: 0, 343: 0, 344: 0, 345: 0, 346: 0, 347: 0, 348: 0, 349: 0, 350: 0, 351: 0, 352: 0, 353: 0, 354: 0, 355: 0, 356: 0, 357: 0, 358: 0, 359: 0, 360: 0, 361: 0, 362: 0, 363: 0, 364: 0, 365: 0, 366: 0, 367: 0, 368: 0, 369: 0, 370: 0, 371: 0, 372: 0, 373: 0, 374: 0, 375: 0, 376: 0, 377: 0, 378: 0, 379: 0, 380: 0, 381: 0, 382: 0, 383: 0, 384: 0, 385: 0, 386: 0, 387: 0, 388: 0, 389: 0, 390: 0, 391: 0, 392: 0, 393: 0, 394: 0, 395: 0, 396: 0, 397: 0, 398: 0, 399: 0, 400: 0, 401: 0, 402: 0, 403: 0, 404: 0, 405: 0, 406: 0, 407: 0, 408: 0, 409: 0, 410: 0, 411: 0, 412: 0, 413: 0, 414: 0, 415: 0, 416: 0, 417: 0, 418: 0, 419: 0, 420: 0, 421: 0, 422: 0, 423: 0, 424: 0, 425: 0, 426: 0, 427: 0, 428: 0, 429: 0, 430: 0, 431: 0, 432: 0, 433: 0, 434: 0, 435: 0, 436: 0, 437: 0, 438: 0, 439: 0, 440: 0, 441: 0, 442: 0, 443: 0, 444: 0, 445: 0, 446: 0, 447: 0, 448: 0, 449: 0, 450: 0, 451: 1}\n"
     ]
    }
   ],
   "source": [
    "rank = 6\n",
    "\n",
    "mtype = \"small_world\"\n",
    "n = 7020\n",
    "# G = nx.connected_watts_strogatz_graph(n, k=4, p=0.1)\n",
    "# G.remove_edges_from(nx.selfloop_edges(G))\n",
    "# G = nx.DiGraph(G)\n",
    "\n",
    "beta = 0.7\n",
    "gamma = 0.01\n",
    "G = nx.scale_free_graph(n, alpha=1-beta-gamma, beta=beta, gamma=gamma)#alpha=0.41, beta=0.54)\n",
    "\n",
    "n = G.number_of_nodes()\n",
    "print(f\"{n=}, {G.number_of_edges()=}\")\n",
    "\n",
    "# for u, v in G.edges():\n",
    "#     G[u][v]['weight'] = np.random.rand() * 10\n",
    "\n",
    "Adj, Dist, nodes_cc = ldr.nx_graph_to_matrices(G, nodes=True)\n",
    "G = G.subgraph(nodes_cc)\n",
    "n = G.number_of_nodes()\n",
    "A = Dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ldr.plot_nx_G(G, with_labels=False, node_size=1, f_layout=nx.spring_layout, width=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.00388619, 0.24021957, 0.22737664, 0.02706734, 0.00145025]),\n",
       " array([ 0.,  2.,  4.,  6.,  8., 10.]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert nx.is_strongly_connected(G)\n",
    "np.histogram(Dist.flatten(), bins=5, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_list = ldr.adjacency_directed_list(Adj)\n",
    "sources, targets = ldr.st_pairs(n, Dist, 1020)\n",
    "M = min(1000, sources.size)\n",
    "sources = sources[:M]\n",
    "targets = targets[:M]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "symm=False\n"
     ]
    }
   ],
   "source": [
    "PSD = False\n",
    "w_min = A[A>0].min()\n",
    "rt_max_iters = min(int(5*A.max()/w_min), (10**4) // 2)\n",
    "symm = np.allclose(A, A.T)\n",
    "print(f\"{symm=}\")\n",
    "filename = \"%s_r%d_%d\"%(mtype, rank, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.22064092e-02, 9.26482673e-06, 0.00000000e+00, 4.63241337e-06,\n",
       "        4.63241337e-06]),\n",
       " array([  1. ,  82.8, 164.6, 246.4, 328.2, 410. ]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(Adj[Adj>0], bins=5, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = {} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PASSED\n"
     ]
    }
   ],
   "source": [
    "fraction_of_nodes = 0.1\n",
    "pi_rows = np.random.permutation(n)[:int(n * fraction_of_nodes)]\n",
    "pi_cols = pi_rows #np.random.permutation(n)[:int(n * fraction_of_nodes)]\n",
    "\n",
    "pi_row_Dist = ldr.sparse_sampled_matrix(pi_rows, Dist, rows=True)\n",
    "pi_col_Dist_T = ldr.sparse_sampled_matrix(pi_cols, Dist, rows=False)\n",
    "\n",
    "rDist = np.zeros((n, n))\n",
    "rDist[pi_rows] = Dist[pi_rows]\n",
    "assert np.allclose(pi_row_Dist.toarray(), rDist)\n",
    "\n",
    "cDist = np.zeros((n, n))\n",
    "cDist[:, pi_cols] = Dist[:, pi_cols]\n",
    "assert np.allclose(pi_col_Dist_T.T.toarray(), cDist)\n",
    "print(\"PASSED\")\n",
    "\n",
    "rDist = Dist[pi_rows]\n",
    "cDist = Dist[:, pi_cols].T\n",
    "\n",
    "pi_rows_c = np.delete(np.arange(n), pi_rows)\n",
    "pi_cols_c = np.delete(np.arange(n), pi_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Symmetric fit -> split -> asymmetric fit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n",
      "/Users/parshakova.tanya/Documents/projects/lr_distributed_routing/lrrouting/cg.py:48: NumbaPerformanceWarning: \u001b[1m\u001b[1m\u001b[1mnp.dot() is faster on contiguous arrays, called on (array(float64, 1d, A), array(float64, 1d, C))\u001b[0m\u001b[0m\u001b[0m\n",
      "  rho0 = np.dot(r, z)\n",
      "/Users/parshakova.tanya/Documents/projects/lr_distributed_routing/lrrouting/cg.py:72: NumbaPerformanceWarning: \u001b[1m\u001b[1m\u001b[1mnp.dot() is faster on contiguous arrays, called on (array(float64, 1d, A), array(float64, 1d, A))\u001b[0m\u001b[0m\u001b[0m\n",
      "  losses[k] = np.sqrt(np.dot(r, r)) / b_norm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "rank/2=3.0, loss=1.0430089654218087\n",
      "median_stretch=300.0%, mean_stretch=594.5%\n",
      "%[ratio<2] = 40.60%, %[ratio<1.2] = 24.90%, %[ratio=1.] = 24.20%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nSymmetric fit -> split -> asymmetric fit\")\n",
    "# get symmetric embedding\n",
    "X_symm, loss, losses = ldr.fast_cc(rank//2, pi_rows=pi_rows, pi_rows_c=pi_rows_c, rDist=rDist, #rDist=(rDist+cDist)/2, \n",
    "                               symm=True, n_init=5,\n",
    "                               max_iter=1000, eps=1e-6, verbose=False, freq=500, cg_eps=1e-20, cg_max_iter=1000)\n",
    "print(f\"\\n{rank/2=}, {loss=}\")\n",
    "l_dar = ldr.construct_node_embedding_graph(X_symm, adjacency_list)\n",
    "_ = {'ratios' : ldr.subopt_ratios(l_dar, Dist, sources, targets)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Symmetric fit -> split -> asymmetric fit\n",
      "\n",
      "rank/2=3.0, loss=0.9846596731259017\n",
      "median_stretch=225.0%, mean_stretch=484.5%\n",
      "%[ratio<2] = 48.90%, %[ratio<1.2] = 30.40%, %[ratio=1.] = 29.80%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nSymmetric fit -> split -> asymmetric fit\")\n",
    "# get symmetric embedding\n",
    "X_symm, loss, losses = ldr.slow_cc(rank//2, pi_rows=pi_rows, rDist=rDist,#rDist=(rDist+cDist)/2, \n",
    "                               symm=True, n_init=2, debug=True,\n",
    "                               max_iter=1000, eps=1e-6, verbose=False, freq=500)\n",
    "print(f\"\\n{rank/2=}, {loss=}\")\n",
    "l_dar = ldr.construct_node_embedding_graph(X_symm, adjacency_list)\n",
    "_ = {'ratios' : ldr.subopt_ratios(l_dar, Dist, sources, targets)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z0 = np.concatenate([X_symm, X_symm], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "rank/2=3.0, loss=0.34452660751844494\n",
      "median_stretch=133.3%, mean_stretch=480.5%\n",
      "%[ratio<2] = 56.60%, %[ratio<1.2] = 47.50%, %[ratio=1.] = 47.10%\n"
     ]
    }
   ],
   "source": [
    "# split and fit asymmetric embedding\n",
    "Z, loss, losses = ldr.slow_cc(rank, pi_rows=pi_rows, pi_cols=pi_cols, rDist=rDist, cDist=cDist, \n",
    "                               symm=False, n_init=2, debug=True, Z0=Z0,\n",
    "                               max_iter=1000, eps=1e-6, verbose=False, freq=500)\n",
    "print(f\"\\n{rank/2=}, {loss=}\")\n",
    "l_dar = ldr.construct_xy_node_embedding_graph(Z[:n], Z[n:], adjacency_list)\n",
    "_ = {'ratios' : ldr.subopt_ratios(l_dar, Dist, sources, targets)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "rank=6, loss=0.34452660751843034\n",
      "$\\|x_i-y_j\\|_2$\n",
      "median_stretch=133.3%, mean_stretch=480.7%\n",
      "%[ratio<2] = 56.60%, %[ratio<1.2] = 47.50%, %[ratio=1.] = 47.10%\n"
     ]
    }
   ],
   "source": [
    "# split and fit asymmetric embedding\n",
    "Z0 = np.concatenate([X_symm, X_symm], axis=0)\n",
    "assert not np.isnan(Z0).any()\n",
    "# Z2 = np.random.randn(2*n, rank//2)\n",
    "Z, loss, losses = ldr.fast_cc(rank, pi_rows=pi_rows, pi_cols=pi_cols, pi_rows_c=pi_rows_c, pi_cols_c=pi_cols_c, rDist=rDist, \n",
    "                              cDist=cDist, Z0=Z0, n_init=1,\n",
    "                              max_iter=1000, eps=1e-10, verbose=False, freq=500, cg_eps=1e-20, cg_max_iter=1000)\n",
    "print(f\"\\n{rank=}, {loss=}\")\n",
    "print(r\"$\\|x_i-y_j\\|_2$\")\n",
    "l_dar = ldr.construct_xy_node_embedding_graph(Z[:n], Z[n:], adjacency_list)\n",
    "_ = {'ratios' : ldr.subopt_ratios(l_dar, Dist, sources, targets)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median_stretch=333.3%, mean_stretch=578.4%\n",
      "%[ratio<2] = 40.30%, %[ratio<1.2] = 26.20%, %[ratio=1.] = 25.50%\n"
     ]
    }
   ],
   "source": [
    "l_dar = ldr.construct_node_embedding_graph(Z[:n], adjacency_list)\n",
    "_ = {'ratios' : ldr.subopt_ratios(l_dar, Dist, sources, targets)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Symmetric fit -> split -> asymmetric fit\n",
      "\n",
      "rank/2=2.0, losses[0]=9.715870736654784, losses[-1]=0.0\n",
      "median_stretch=375.0%, mean_stretch=608.8%\n",
      "%[ratio<2] = 32.40%, %[ratio<1.2] = 18.30%, %[ratio=1.] = 17.90%\n",
      "\n",
      "rank=4, losses[0]=2.2439133292048843, losses[-1]=0.5449817057131584\n",
      "$\\|x_i-y_j\\|_2$\n",
      "median_stretch=200.0%, mean_stretch=530.1%\n",
      "%[ratio<2] = 50.90%, %[ratio<1.2] = 32.10%, %[ratio=1.] = 30.30%\n",
      "\n",
      "\n",
      "Asymmetric fit\n",
      "\n",
      "rank=4, losses[0]=11.61309832219528, losses[-1]=0.0\n",
      "$\\|x_i-y_j\\|_2$\n",
      "median_stretch=129.2%, mean_stretch=370.2%\n",
      "%[ratio<2] = 64.90%, %[ratio<1.2] = 46.40%, %[ratio=1.] = 45.10%\n",
      "$\\|x_i-x_j\\|_2$\n",
      "median_stretch=333.3%, mean_stretch=568.7%\n",
      "%[ratio<2] = 38.00%, %[ratio<1.2] = 22.40%, %[ratio=1.] = 21.70%\n",
      "$\\|y_i-y_j\\|_2$\n",
      "median_stretch=300.0%, mean_stretch=545.2%\n",
      "%[ratio<2] = 41.10%, %[ratio<1.2] = 23.40%, %[ratio=1.] = 22.70%\n",
      "\n",
      "\n",
      "Symmetric fit -> split -> asymmetric fit\n",
      "\n",
      "rank/2=4.0, losses[0]=5.181272940840443, losses[-1]=0.4051804087105434\n",
      "median_stretch=310.0%, mean_stretch=525.7%\n",
      "%[ratio<2] = 40.70%, %[ratio<1.2] = 27.10%, %[ratio=1.] = 26.60%\n",
      "\n",
      "rank=8, losses[0]=1.795431074253866, losses[-1]=0.2345433673120401\n",
      "$\\|x_i-y_j\\|_2$\n",
      "median_stretch=100.0%, mean_stretch=435.5%\n",
      "%[ratio<2] = 65.00%, %[ratio<1.2] = 54.70%, %[ratio=1.] = 54.10%\n",
      "\n",
      "\n",
      "Asymmetric fit\n",
      "\n",
      "rank=8, losses[0]=6.981795203904057, losses[-1]=0.2657382021611024\n",
      "$\\|x_i-y_j\\|_2$\n",
      "median_stretch=133.3%, mean_stretch=430.1%\n",
      "%[ratio<2] = 57.00%, %[ratio<1.2] = 41.90%, %[ratio=1.] = 41.40%\n",
      "$\\|x_i-x_j\\|_2$\n",
      "median_stretch=336.7%, mean_stretch=578.2%\n",
      "%[ratio<2] = 40.30%, %[ratio<1.2] = 28.10%, %[ratio=1.] = 27.20%\n",
      "$\\|y_i-y_j\\|_2$\n",
      "median_stretch=166.7%, mean_stretch=425.8%\n",
      "%[ratio<2] = 58.50%, %[ratio<1.2] = 37.10%, %[ratio=1.] = 35.60%\n",
      "\n",
      "\n",
      "Symmetric fit -> split -> asymmetric fit\n",
      "\n",
      "rank/2=8.0, losses[0]=3.215328445839707, losses[-1]=0.19475950029893332\n",
      "median_stretch=233.3%, mean_stretch=463.1%\n",
      "%[ratio<2] = 47.10%, %[ratio<1.2] = 30.50%, %[ratio=1.] = 30.00%\n",
      "\n",
      "rank=16, losses[0]=1.6621764027624566, losses[-1]=0.13803165151492996\n",
      "$\\|x_i-y_j\\|_2$\n",
      "median_stretch=125.0%, mean_stretch=395.7%\n",
      "%[ratio<2] = 68.60%, %[ratio<1.2] = 49.30%, %[ratio=1.] = 47.30%\n",
      "\n",
      "\n",
      "Asymmetric fit\n",
      "\n",
      "rank=16, losses[0]=5.049124059823806, losses[-1]=0.14191835059970404\n",
      "$\\|x_i-y_j\\|_2$\n",
      "median_stretch=100.0%, mean_stretch=384.0%\n",
      "%[ratio<2] = 72.60%, %[ratio<1.2] = 59.90%, %[ratio=1.] = 58.40%\n",
      "$\\|x_i-x_j\\|_2$\n",
      "median_stretch=275.0%, mean_stretch=526.0%\n",
      "%[ratio<2] = 44.00%, %[ratio<1.2] = 30.30%, %[ratio=1.] = 29.50%\n",
      "$\\|y_i-y_j\\|_2$\n",
      "median_stretch=150.0%, mean_stretch=333.8%\n",
      "%[ratio<2] = 62.30%, %[ratio<1.2] = 41.10%, %[ratio=1.] = 39.10%\n",
      "\n",
      "\n",
      "Symmetric fit -> split -> asymmetric fit\n",
      "\n",
      "rank/2=10.0, losses[0]=4.2111912370534235, losses[-1]=0.1692405086272793\n",
      "median_stretch=200.0%, mean_stretch=431.8%\n",
      "%[ratio<2] = 53.30%, %[ratio<1.2] = 35.50%, %[ratio=1.] = 34.50%\n",
      "\n",
      "rank=20, losses[0]=1.6422278856040717, losses[-1]=0.11339454502612822\n",
      "$\\|x_i-y_j\\|_2$\n",
      "median_stretch=100.0%, mean_stretch=347.6%\n",
      "%[ratio<2] = 70.30%, %[ratio<1.2] = 57.50%, %[ratio=1.] = 56.80%\n",
      "\n",
      "\n",
      "Asymmetric fit\n",
      "\n",
      "rank=20, losses[0]=5.980077672149044, losses[-1]=0.11443910228290909\n",
      "$\\|x_i-y_j\\|_2$\n",
      "median_stretch=100.0%, mean_stretch=331.1%\n",
      "%[ratio<2] = 74.50%, %[ratio<1.2] = 63.70%, %[ratio=1.] = 62.70%\n",
      "$\\|x_i-x_j\\|_2$\n",
      "median_stretch=266.7%, mean_stretch=528.9%\n",
      "%[ratio<2] = 45.90%, %[ratio<1.2] = 31.10%, %[ratio=1.] = 30.10%\n",
      "$\\|y_i-y_j\\|_2$\n",
      "median_stretch=133.3%, mean_stretch=314.7%\n",
      "%[ratio<2] = 65.80%, %[ratio<1.2] = 46.30%, %[ratio=1.] = 44.30%\n"
     ]
    }
   ],
   "source": [
    "for rank in [4, 8, 16, 20]:\n",
    "    print(\"\\n\\nSymmetric fit -> split -> asymmetric fit\")\n",
    "    # get symmetric embedding\n",
    "    Z_symm, loss, losses = ldr.fast_cc(rank//2, pi_rows=pi_rows, pi_rows_c=pi_rows_c, rDist=(rDist+cDist)/2, symm=True, n_init=5,\n",
    "                                        max_iter=1000, eps=1e-6, verbose=False, freq=500)\n",
    "    print(f\"\\n{rank/2=}, {losses[0]=}, {losses[-1]=}\")\n",
    "    # split and fit asymmetric embedding\n",
    "    l_dar = ldr.construct_node_embedding_graph(Z_symm, adjacency_list)\n",
    "    _ = {'ratios' : ldr.subopt_ratios(l_dar, Dist, sources, targets)}\n",
    "    Z0 = np.concatenate([Z_symm, Z_symm], axis=0)\n",
    "    Z, loss, losses = ldr.fast_cc(rank, pi_rows, pi_cols, pi_rows_c, pi_cols_c, rDist, cDist, Z0=Z0, n_init=1,\n",
    "                                    max_iter=1000, eps=1e-10, verbose=False, freq=500, cg_eps=1e-7, cg_max_iter=1000)\n",
    "    print(f\"\\n{rank=}, {losses[0]=}, {losses[-1]=}\")\n",
    "    print(r\"$\\|x_i-y_j\\|_2$\")\n",
    "    l_dar = ldr.construct_xy_node_embedding_graph(Z[:n], Z[n:], adjacency_list)\n",
    "    _ = {'ratios' : ldr.subopt_ratios(l_dar, Dist, sources, targets)}\n",
    "\n",
    "\n",
    "    print(\"\\n\\nAsymmetric fit\")\n",
    "    Z, loss, losses = ldr.fast_cc(rank, pi_rows, pi_cols, pi_rows_c, pi_cols_c, rDist, cDist, n_init=2, \n",
    "                                  max_iter=1000, eps=1e-6, verbose=False, freq=500, cg_eps=1e-7, cg_max_iter=1000)\n",
    "    print(f\"\\n{rank=}, {losses[0]=}, {losses[-1]=}\")\n",
    "    print(r\"$\\|x_i-y_j\\|_2$\")\n",
    "    l_dar = ldr.construct_xy_node_embedding_graph(Z[:n], Z[n:], adjacency_list)\n",
    "    _ = {'ratios' : ldr.subopt_ratios(l_dar, Dist, sources, targets)}\n",
    "    print(r\"$\\|x_i-x_j\\|_2$\")\n",
    "    l_dar = ldr.construct_node_embedding_graph(Z[:n], adjacency_list)\n",
    "    _ = {'ratios' : ldr.subopt_ratios(l_dar, Dist, sources, targets)}\n",
    "    print(r\"$\\|y_i-y_j\\|_2$\")\n",
    "    l_dar = ldr.construct_node_embedding_graph(Z[n:], adjacency_list)\n",
    "    _ = {'ratios' : ldr.subopt_ratios(l_dar, Dist, sources, targets)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43620244217962734"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.rel_diff(Dist, Dist.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Symmetric fit -> split -> asymmetric fit\n",
      "\n",
      "rank/2=2.0, losses[0]=13.123036978815625, losses[-1]=0.0\n",
      "median_stretch=366.7%, mean_stretch=655.5%\n",
      "%[ratio<2] = 37.30%, %[ratio<1.2] = 21.10%, %[ratio=1.] = 19.50%\n",
      "\n",
      "rank=4, losses[0]=3.4615732413023754, losses[-1]=0.0\n",
      "$\\|x_i-y_j\\|_2$\n",
      "median_stretch=250.0%, mean_stretch=515.7%\n",
      "%[ratio<2] = 47.10%, %[ratio<1.2] = 30.90%, %[ratio=1.] = 30.30%\n",
      "\n",
      "\n",
      "Asymmetric fit\n",
      "\n",
      "rank=4, losses[0]=11.696765920545753, losses[-1]=0.6171095725940461\n",
      "$\\|x_i-y_j\\|_2$\n",
      "median_stretch=150.0%, mean_stretch=440.6%\n",
      "%[ratio<2] = 62.00%, %[ratio<1.2] = 37.60%, %[ratio=1.] = 36.50%\n",
      "$\\|x_i-x_j\\|_2$\n",
      "median_stretch=333.3%, mean_stretch=592.3%\n",
      "%[ratio<2] = 39.50%, %[ratio<1.2] = 26.50%, %[ratio=1.] = 26.10%\n",
      "$\\|y_i-y_j\\|_2$\n",
      "median_stretch=300.0%, mean_stretch=584.7%\n",
      "%[ratio<2] = 36.90%, %[ratio<1.2] = 20.90%, %[ratio=1.] = 20.30%\n",
      "\n",
      "\n",
      "Symmetric fit -> split -> asymmetric fit\n",
      "\n",
      "rank/2=4.0, losses[0]=7.001875123337862, losses[-1]=0.8085108752535417\n",
      "median_stretch=233.3%, mean_stretch=549.1%\n",
      "%[ratio<2] = 47.40%, %[ratio<1.2] = 28.90%, %[ratio=1.] = 28.20%\n",
      "\n",
      "rank=8, losses[0]=3.159724382131097, losses[-1]=0.24060004320296063\n",
      "$\\|x_i-y_j\\|_2$\n",
      "median_stretch=100.0%, mean_stretch=398.1%\n",
      "%[ratio<2] = 69.10%, %[ratio<1.2] = 56.70%, %[ratio=1.] = 55.40%\n",
      "\n",
      "\n",
      "Asymmetric fit\n",
      "\n",
      "rank=8, losses[0]=6.767835776362397, losses[-1]=0.2594445000404034\n",
      "$\\|x_i-y_j\\|_2$\n",
      "median_stretch=100.0%, mean_stretch=383.5%\n",
      "%[ratio<2] = 68.70%, %[ratio<1.2] = 56.90%, %[ratio=1.] = 56.10%\n",
      "$\\|x_i-x_j\\|_2$\n",
      "median_stretch=350.0%, mean_stretch=561.1%\n",
      "%[ratio<2] = 39.60%, %[ratio<1.2] = 25.40%, %[ratio=1.] = 24.50%\n",
      "$\\|y_i-y_j\\|_2$\n",
      "median_stretch=175.0%, mean_stretch=442.4%\n",
      "%[ratio<2] = 53.90%, %[ratio<1.2] = 35.50%, %[ratio=1.] = 33.70%\n",
      "\n",
      "\n",
      "Symmetric fit -> split -> asymmetric fit\n",
      "\n",
      "rank/2=8.0, losses[0]=5.3337617135010955, losses[-1]=0.5263226723013604\n",
      "median_stretch=160.0%, mean_stretch=399.7%\n",
      "%[ratio<2] = 59.70%, %[ratio<1.2] = 39.60%, %[ratio=1.] = 38.60%\n",
      "\n",
      "rank=16, losses[0]=3.0380032908556474, losses[-1]=0.13336762564535035\n",
      "$\\|x_i-y_j\\|_2$\n",
      "median_stretch=100.0%, mean_stretch=431.0%\n",
      "%[ratio<2] = 67.30%, %[ratio<1.2] = 54.30%, %[ratio=1.] = 52.20%\n",
      "\n",
      "\n",
      "Asymmetric fit\n",
      "\n",
      "rank=16, losses[0]=4.491141886634999, losses[-1]=0.1388092053458267\n",
      "$\\|x_i-y_j\\|_2$\n",
      "median_stretch=100.0%, mean_stretch=354.9%\n",
      "%[ratio<2] = 71.60%, %[ratio<1.2] = 60.10%, %[ratio=1.] = 59.20%\n",
      "$\\|x_i-x_j\\|_2$\n",
      "median_stretch=300.0%, mean_stretch=509.4%\n",
      "%[ratio<2] = 43.10%, %[ratio<1.2] = 31.50%, %[ratio=1.] = 30.70%\n",
      "$\\|y_i-y_j\\|_2$\n",
      "median_stretch=150.0%, mean_stretch=352.3%\n",
      "%[ratio<2] = 62.00%, %[ratio<1.2] = 42.60%, %[ratio=1.] = 40.70%\n",
      "\n",
      "\n",
      "Symmetric fit -> split -> asymmetric fit\n",
      "\n",
      "rank/2=10.0, losses[0]=6.456412009236686, losses[-1]=0.49562039716367967\n",
      "median_stretch=150.0%, mean_stretch=367.8%\n",
      "%[ratio<2] = 58.60%, %[ratio<1.2] = 40.50%, %[ratio=1.] = 39.10%\n",
      "\n",
      "rank=20, losses[0]=3.0182262748392206, losses[-1]=0.11477401122763459\n",
      "$\\|x_i-y_j\\|_2$\n",
      "median_stretch=100.0%, mean_stretch=400.3%\n",
      "%[ratio<2] = 70.70%, %[ratio<1.2] = 59.60%, %[ratio=1.] = 58.00%\n",
      "\n",
      "\n",
      "Asymmetric fit\n",
      "\n",
      "rank=20, losses[0]=5.6184581247773835, losses[-1]=0.11358602196387002\n",
      "$\\|x_i-y_j\\|_2$\n",
      "median_stretch=100.0%, mean_stretch=337.0%\n",
      "%[ratio<2] = 75.30%, %[ratio<1.2] = 62.90%, %[ratio=1.] = 61.80%\n",
      "$\\|x_i-x_j\\|_2$\n",
      "median_stretch=266.7%, mean_stretch=516.2%\n",
      "%[ratio<2] = 43.40%, %[ratio<1.2] = 30.40%, %[ratio=1.] = 29.90%\n",
      "$\\|y_i-y_j\\|_2$\n",
      "median_stretch=146.4%, mean_stretch=305.6%\n",
      "%[ratio<2] = 63.80%, %[ratio<1.2] = 43.50%, %[ratio=1.] = 42.10%\n"
     ]
    }
   ],
   "source": [
    "for rank in [4, 8, 16, 20]:\n",
    "    print(\"\\n\\nSymmetric fit -> split -> asymmetric fit\")\n",
    "    # get symmetric embedding\n",
    "    Z_symm, loss, losses = ldr.fast_cc(rank//2, pi_rows=pi_rows, pi_rows_c=pi_rows_c, rDist=rDist, symm=True, n_init=5,\n",
    "                                        max_iter=1000, eps=1e-6, verbose=False, freq=500)\n",
    "    print(f\"\\n{rank/2=}, {losses[0]=}, {losses[-1]=}\")\n",
    "    # split and fit asymmetric embedding\n",
    "    l_dar = ldr.construct_node_embedding_graph(Z_symm, adjacency_list)\n",
    "    _ = {'ratios' : ldr.subopt_ratios(l_dar, Dist, sources, targets)}\n",
    "    Z0 = np.concatenate([Z_symm, Z_symm], axis=0)\n",
    "    Z, loss, losses = ldr.fast_cc(rank, pi_rows, pi_cols, pi_rows_c, pi_cols_c, rDist, cDist, Z0=Z0, n_init=2,\n",
    "                                    max_iter=1000, eps=1e-6, verbose=False, freq=500, cg_eps=1e-7, cg_max_iter=1000)\n",
    "    print(f\"\\n{rank=}, {losses[0]=}, {losses[-1]=}\")\n",
    "    print(r\"$\\|x_i-y_j\\|_2$\")\n",
    "    l_dar = ldr.construct_xy_node_embedding_graph(Z[:n], Z[n:], adjacency_list)\n",
    "    _ = {'ratios' : ldr.subopt_ratios(l_dar, Dist, sources, targets)}\n",
    "\n",
    "\n",
    "    print(\"\\n\\nAsymmetric fit\")\n",
    "    Z, loss, losses = ldr.fast_cc(rank, pi_rows, pi_cols, pi_rows_c, pi_cols_c, rDist, cDist, n_init=2, \n",
    "                                  max_iter=1000, eps=1e-6, verbose=False, freq=500, cg_eps=1e-7, cg_max_iter=1000)\n",
    "    print(f\"\\n{rank=}, {losses[0]=}, {losses[-1]=}\")\n",
    "    print(r\"$\\|x_i-y_j\\|_2$\")\n",
    "    l_dar = ldr.construct_xy_node_embedding_graph(Z[:n], Z[n:], adjacency_list)\n",
    "    _ = {'ratios' : ldr.subopt_ratios(l_dar, Dist, sources, targets)}\n",
    "    print(r\"$\\|x_i-x_j\\|_2$\")\n",
    "    l_dar = ldr.construct_node_embedding_graph(Z[:n], adjacency_list)\n",
    "    _ = {'ratios' : ldr.subopt_ratios(l_dar, Dist, sources, targets)}\n",
    "    print(r\"$\\|y_i-y_j\\|_2$\")\n",
    "    l_dar = ldr.construct_node_embedding_graph(Z[n:], adjacency_list)\n",
    "    _ = {'ratios' : ldr.subopt_ratios(l_dar, Dist, sources, targets)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "routing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
